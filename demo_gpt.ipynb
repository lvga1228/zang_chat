{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7de78ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape = torch.Size([1, 8, 50304])\n",
      "generated tokens: [41693, 48386, 45991, 30677, 44781, 4432, 9928, 27779, 11887, 13594, 36881, 18860, 1525, 5615, 7025, 38210, 13532, 21643, 2617, 11829, 42336, 15820, 28877, 35653, 3148, 17919, 16056, 40292, 1479, 42529, 3296, 17112, 1079, 10295, 26547, 15718, 5539, 1353, 43100, 14184, 40857, 13295, 27767, 50160, 18592, 7006, 23971, 46121, 8315, 23160, 462, 6347, 25002, 43092, 23513, 10523, 3170, 47475, 26995, 27967, 9339, 40890, 698, 11797, 20573, 11032, 40830, 40777, 21022, 37033, 11199, 4367, 45815, 15854, 36626, 3581, 37314, 17447, 13235, 43774, 45841, 49312, 28840, 34560, 30756, 22830, 24173, 5748, 7840, 45678, 24717, 7547, 37450, 13947, 33441, 16765, 47723, 8744, 4298, 32311]\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from zangchat.gpt import GPT, GPT_Config  # 注意用修正后的名字\n",
    "\n",
    "def main():\n",
    "    config = GPT_Config \n",
    "    model = GPT(config)\n",
    "    model.init_weights()\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 假造一批 token\n",
    "    idx = torch.randint(0, config.vocab_size, (1, 8), device=device)  # (B=1, T=8)\n",
    "    logits = model(idx)\n",
    "    print(\"logits.shape =\", logits.shape)  # 期望: (1, 8, vocab_size)\n",
    "\n",
    "    # 测试 generate\n",
    "    tokens = [1, 2, 3,4,4,4,4,4,7,7,7,3,2,1,3,4,5,6,6]\n",
    "    out = []\n",
    "    for t in model.generate(tokens, max_tokens=100, temperature=0.5):\n",
    "        out.append(t)\n",
    "    print(\"generated tokens:\", out)\n",
    "    print(device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18abcb",
   "metadata": {},
   "source": [
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4772c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanochat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
